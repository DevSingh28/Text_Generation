{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSeSC3Jqf5/uSiW46gJbja",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevSingh28/Text_Generation/blob/main/Text_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9p1-TivHsDAs"
      },
      "outputs": [],
      "source": [
        "# Libraries and Modules Used:\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from tqdm.auto import tqdm\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ocn2OkKqz1Ww",
        "outputId": "c630b8e3-91cc-4392-c3f7-0afb92880847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading datasets-3.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.0.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Dataset\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"daily_dialog\")\n",
        "data = dataset['train'].shuffle(seed=42).select(range(int(len(dataset['train']) * 0.1)))\n",
        "\n",
        "for i in range(5):\n",
        "    print(data[i])\n",
        "\n",
        "data = ' '.join([' '.join(dialogue['dialog']) for dialogue in data])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489,
          "referenced_widgets": [
            "712b12ae509d4da68003bbb6ffb677e1",
            "bb48ddc037a2421c8084da648b0c3784",
            "c887a464b14e40929363178db03ad1df",
            "9d585e51af9c4f078777dbc7e4efb4ce",
            "a568965b54234ebda179af16a44057d6",
            "3d46772b40474e6a8fd3b26771e99403",
            "f2a1eda9b64c4463a15ec4208064f94a",
            "f7d2394b06494e35b51aacf68d620196",
            "dddacaf67a1a438687d67aad48587547",
            "1edd3e4a30274b139db36cb09b44d193",
            "a9df06a348e24dc9bc72a886409dc150",
            "4e75e24eef7f4a0596a31b0089b13a60",
            "4c3ea7ffba6a43b289d4ecfa5a580eba",
            "40100d87eb974f14bcb8ba16fac7cf90",
            "b81b5377fdba4551b5d6d255435e2892",
            "793d9d5ff44847e38465b1aad50ee151",
            "d82ed188e9ba4b37af0473713c9d813f",
            "82aef3be7e7d4acebe4b316c50d8214b",
            "72a42e1341294817b3c05541b315c0af",
            "79b5eacfe0854e94ab07e1f833729e02",
            "f8b4e2d710f1475581101a637409bd96",
            "87b389ce037d4e76a7aad116e88d258a",
            "6f292ef61268426697b8a62eca5c5d67",
            "fb88f436cc7a4658a32760cd49ec68c8",
            "7bd867d9f1234c829750d80d4c5e6382",
            "38be367253374dd398e0a87ad29280c5",
            "6580dcd7240b45be8f62974943353ee1",
            "c0e38456cbc74da5b0472ae3bf5ba27f",
            "2cd5c6ccda4a49fba96cf0f477a6da2b",
            "870fc6aaa3164c3c9190aa71660974f4",
            "0faf5e2c870e4d19af861bb821c34977",
            "c94b6297fd334155b7c5de73dc80b679",
            "c7cd2577f229484788ac34eddf682e57",
            "0532b19afb9d465da241db4cd13cd11e",
            "438cb93d8e1242008480db4bbbdb6c6d",
            "4720604a49c84c50af3650be357f91cd",
            "5e86eaca6c7447ea9cfd95382875e2f3",
            "24a95ee7c6eb4d8499b3b91af5dc47bb",
            "959dbfaef4264d0f88cae30bbcf143b4",
            "84b5fa1947054dee8fff18e552caad9d",
            "2b72c404bbf8439db64a532280c38bbd",
            "c3ba6019abb04e0c90b40008b42dca78",
            "037ef328b0e24f2d85fdc99d7a019cc6",
            "73c10a75312e4fb6bd38b2440d4a4ff8",
            "4b18a2a1806a4c51ac718ec085584976",
            "011df71f487343f09119a586b766a4a5",
            "504458554f4e4d1a9f60edf56d1546f1",
            "ba6319d9c5ae4bb39b53b723d23b3b29",
            "ae2f1c1b8d574dd483315787189551cf",
            "5a2370ea506e4797880a31e926dce034",
            "c8f1d8c8d6d846899b695662520f2fcd",
            "41bb9bee249d4fe989d95c5f8116f325",
            "3b81c76bf85a4d8e915667828258ca69",
            "fc0f13ebf2384722b396a3c7792da344",
            "aa8b3bff333043579fc05ea1ab6c604a",
            "f72af25c094a4edab02829871ac010fb",
            "64c21f1ba7a74fb382f5595d7f7c42e8",
            "d2e528d6699d4f12af6cdbf2b073c261",
            "19018d91c0b640d18f2e7cba88fcbf6e",
            "35d1dcdf247b48a1bf935a0271a9f9dd",
            "c90f0835a3874ff69e88ae1ab67c78b6",
            "29f90ce9d46f43f18d2241c60ff22712",
            "e7b778d853e5455d99e1b5766009eb14",
            "84caf59ff13643e483adb1d6eadde068",
            "fc20cbf18b524046a0ed3df4e510834a",
            "f42e37cf4b5d491a90151eaf6c880276"
          ]
        },
        "id": "skJN3eopzvJY",
        "outputId": "02203a43-24a9-4794-bb04-21f53f97df6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/7.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "712b12ae509d4da68003bbb6ffb677e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "daily_dialog.py:   0%|          | 0.00/4.85k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e75e24eef7f4a0596a31b0089b13a60"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for daily_dialog contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/daily_dialog.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/4.48M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f292ef61268426697b8a62eca5c5d67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/11118 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0532b19afb9d465da241db4cd13cd11e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b18a2a1806a4c51ac718ec085584976"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f72af25c094a4edab02829871ac010fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dialog': [\"finally we're on board ! \", \" yes . It was so crowded . I'm worn-out . Let's find our seats . \", ' are they window seats or aisle seats ? ', ' let me see ... yes , one window seat and one aisle seat . ', \" ok . But can I trade my seat with you ? I prefer the one near the window . I'm a terrible flyer . I always get airsick and can never relax until after I've landed . \", \" that's fine . I'd like to be on the aisle anyway . It's easier to get in and out . \", ' thanks . Where shall we put our luggage ? ', ' I think the smaller carry-on bag can go in the overhead compartment , and the others can go under the seat . ', ' good idea . ', \" don't forget to keep the seat belt on . \", \" ok . Hope it's a pleasant trip . \", ' yes ! ', ' and no hijackers . ', ' oh , you have too wild of an imagination . '], 'act': [1, 3, 2, 1, 3, 4, 2, 1, 1, 3, 4, 1, 1, 1], 'emotion': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "{'dialog': [\"Mary , why don't you come to my house this Saturday ? \", \" I don't know . I'll have to ask my host mom . \", ' Come on , Mary . This is America . You make your own decisions here . ', ' But I still have to tell her . ', ' Of course . ', ' Tell you what , give me your phone number . ', \" It's 555-4321 . \", \" Got it . I'll call you later tonight and we can talk about what to do on Saturday . \"], 'act': [3, 4, 3, 4, 1, 1, 1, 1], 'emotion': [0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "{'dialog': ['How good are you at sports , Bill ? ', ' Are you kidding ? I ’ m terrible ! But I love to watch sports . I go to football or baseball games a lot . And I read sports magazines every week . ', ' Wow ! ', ' Do you like sports , Janice ? ', ' Oh , yes . I like to exercise . But I don ’ t watch sports or buy sports magazines . I don ’ t have much time to do those things . ', ' Oh , I see . You know , we spend time doing different sports . How much time do you spend exercising ? ', ' Well , I guess I exercise about two hours a day . I do aerobics three times a week , and the other days I play badminton 1 with my husband . I always feel good afterward . ', ' That ’ s great ! I ’ Ve heard people say that before . ', ' Well , why don ’ t you try to get some exercise ? It ’ s difficult , but very rewarding . ', ' Oh , I ’ m too lazy to play sports , and I ’ m not good at anything either . It hardly excites me . '], 'act': [2, 2, 1, 2, 1, 2, 1, 1, 2, 1], 'emotion': [0, 6, 0, 0, 0, 0, 0, 4, 0, 0]}\n",
            "{'dialog': ['Personnel . May I help you ? ', ' Hi , could I speak to Nancy please ? ', ' This is she . Paul ? ', ' Yeah , it ’ s me . Can you give me a lift after work ? '], 'act': [2, 3, 2, 3], 'emotion': [0, 0, 0, 0]}\n",
            "{'dialog': ['Well , what brings you here ? ', ' I came to see my aunt . ', ' Does she live nearby ? ', ' Yes . She lives on the next block . '], 'act': [2, 1, 2, 1], 'emotion': [0, 0, 0, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyYZi2g82AVB",
        "outputId": "b41d2c4a-04b4-4694-8332-ac13019fe1c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the data\n",
        "\n",
        "chars = sorted(list(set(data)))\n",
        "vocab_size = len(chars)\n",
        "print(vocab_size)\n",
        "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
        "idx_to_char = {i: ch for i, ch in enumerate(chars)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkj7msoYuMVi",
        "outputId": "0294e8a8-cd43-4f16-bcc9-03d006591ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ_9Po-GEXkV",
        "outputId": "1478ade3-b9cf-459e-ff7c-9316bad4c081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ',\n",
              " '!',\n",
              " '\"',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " '\\\\',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '£',\n",
              " '–',\n",
              " '—',\n",
              " '‘',\n",
              " '’',\n",
              " '“',\n",
              " '”',\n",
              " '。']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "\n",
        "embedding_size = 64\n",
        "num_heads = 4\n",
        "num_layers = 2\n",
        "hidden_size = 256\n",
        "seq_length = 12\n",
        "batch_size = 64\n",
        "learning_rate = 0.0005\n",
        "num_epochs = 15\n",
        "vocab_size = 87"
      ],
      "metadata": {
        "id": "OmTXouHjuT0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data into input-output pairs for training\n",
        "\n",
        "data_idx = [char_to_idx[ch] for ch in data]\n",
        "inputs = []\n",
        "targets = []\n",
        "\n",
        "for i in range(0, len(data_idx) - seq_length):\n",
        "    inputs.append(data_idx[i:i + seq_length])\n",
        "    targets.append(data_idx[i + 1:i + seq_length + 1])\n",
        "\n",
        "inputs = torch.tensor(inputs, dtype=torch.long).to(device)\n",
        "targets = torch.tensor(targets, dtype=torch.long).to(device)"
      ],
      "metadata": {
        "id": "pFu9KF63ue8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data and using DataLoader for better performance\n",
        "\n",
        "dataset = TensorDataset(inputs, targets)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "p8zGiNBculfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT-like model using Transformer architecture\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, num_heads, hidden_size, num_layers, seq_length):\n",
        "        super(GPTModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.position_embedding = nn.Embedding(seq_length, embedding_size)\n",
        "        self.transformer_layers = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=embedding_size, nhead=num_heads, dim_feedforward=hidden_size, batch_first=True),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.fc_out = nn.Linear(embedding_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_length = x.size(1)\n",
        "        positions = torch.arange(0, seq_length, device=x.device).unsqueeze(0)\n",
        "        x = self.embedding(x) + self.position_embedding(positions)\n",
        "        x = self.transformer_layers(x)\n",
        "        x = self.fc_out(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Mqfy5ZWEuo6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "\n",
        "model = GPTModel(vocab_size, embedding_size, num_heads, hidden_size, num_layers, seq_length).to(device)"
      ],
      "metadata": {
        "id": "tWDIsbusut1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "VWq4SPS_uxQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(inputs) // batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYYwFM2-2ZvV",
        "outputId": "75f67b4e-65e7-40a4-9ab3-2be35dc259b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop with batching\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    with tqdm(total=len(dataloader), desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as pbar:\n",
        "        for batch_inputs, batch_targets in dataloader:\n",
        "            batch_inputs, batch_targets = batch_inputs.to(device), batch_targets.to(device)  # Move to GPU\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_inputs)\n",
        "            loss = criterion(outputs.view(-1, vocab_size), batch_targets.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f'Epoch {epoch + 1}, Average Loss: {avg_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757,
          "referenced_widgets": [
            "d831f31de82b4d08bbf326af06fba5a9",
            "4c9c5593caa049d8bddfe3b8cd514792",
            "3d6f0e1a1fa945b5b4c703f4df1d8b4c",
            "a867d52944eb4619a97d2ef6ca073bea",
            "9890919f60f54ab6af87a6dceb9f61c7",
            "4c0fd581f740448da344743d4bb6020e",
            "7445a53d72e94d2f985b7ab51adaad18",
            "1b20c5f1a6024ec7bc881765fed0fdc1",
            "ea4624a973cb4c7ba616b76aca0e2877",
            "8eef1e9496b54b40a5528a74057f7d6d",
            "3e1bceb364764bd987399d4c339184c4",
            "7aec08851e3f44bfaa728bdfadeaf8ae",
            "9d2d8119dc014732a42db081b5a990cf",
            "37c0eb7b1b1a4e538b1f5a562aaf7aad",
            "ba29c12ae04340d88e44f46a41ea3fb0",
            "a10de4259eef4b5497b8256ced6617ba",
            "cc8fd8ff87e24ec7accd86977ec04a3f",
            "cbd0e44f46b84a7b9fe119384beca095",
            "9c0821f73857453bbaf6f1628e969372",
            "f6af4ba08b6644b78cf3acc80ca5d08e",
            "e3a9b4f130414410a45b07f7c1113e93",
            "5b553bd9f5604e9082d252deae8b0334",
            "1f33d739a6a942c383ec0dd2d4350975",
            "e9cda58ac7814cafa5a69c1c1f709934",
            "4bc62efbe6fe4aca86335fcf065e7a03",
            "2bbff14a4e3b416482fd6a65f05461d6",
            "f3124ce378f745deb9b53ac51301bdb8",
            "dea502c3bb534f63825512ecb525736f",
            "26104c2b8b2245469e524e908dc76a34",
            "a9bbd8bea32b4ceeb31fa858f9a5e13d",
            "c51de968c5e34cffbe6f5ab82eff2870",
            "609602dfeb4f4c3bba777e19f5eb33c0",
            "894f0a4122e7451db7bfd16c23deff7b",
            "280aa54eda924886b3a090ef13c17530",
            "e07b9aa3f2914adeb7926f46e512f9e0",
            "6f1b930512b44f9fbb11b3cfb2b6973a",
            "1feb8f434cab49a3bdeec3886e632ba2",
            "2573fa78536d442ca6696f0f30d84504",
            "339542002fd94e7b829249f9dc24927e",
            "611a004794d4465b8bceec6b880f2eb0",
            "2d90f18b62ce4aa8a54f97f54faac518",
            "f0fa9b5da3ad43c4b9dcddb8f4680876",
            "d54c6f96d3f04251b4fa207b005db172",
            "9f0c584216a24cc2b3ceff74c10a89ec",
            "b2f75395c9f74fed98dd81fcf38292cf",
            "323b2b1efba34c8f8abf7cb697f3a1b4",
            "be70a60d9dcf47ae8a5b8c7a978cf945",
            "0f8eca5ca99947e0ba53e8b6bb452af0",
            "15b47e850c18427dadd6c0e241de0816",
            "c5ac2df67a1e421b962929a88b626c04",
            "c29af973e1b6490aaa5294905e2496d2",
            "a8cf44df39de44a68680571140c329a1",
            "d99023a5d2514c9981b15d718036cc02",
            "1eb7ebd35ea04d0995668d668e5cd682",
            "f4d7401f3b784a2cadd75e26cd38d76b",
            "769db0b4d83948e4ae4f833379ee0f99",
            "5c106ce2b08b442bb0036f0b8c692399",
            "91664836337c48f79598ac2ec2cdeccc",
            "38f033ae220c492cb0d0bed6cedcf178",
            "d9bcbfc4d73c4c5c9b1bf30853641f1a",
            "e9f75df5a70d45d0b2f6c62fe4dc57f4",
            "0192a6685f4f457a978933f89e48da41",
            "e424ff9e36714fec9b968caabbffd815",
            "8772e66c314d46d082704c91775c3b03",
            "2308456ab85741618a1ee4c502acff00",
            "698b145fd06c493a943f19e20c92e7e4",
            "70b6d01efea64b708b816208ee79e95f",
            "bf14dc14594f43a5835572b282b8a9cd",
            "603b98292cac4c6abcf3f079c73b6d70",
            "da9b8c3c05a4475a9c2c25050374ca6e",
            "1fa252e85a094f7281fb077fa9adf2ff",
            "4bb56ddfe8434793940905f85c4b76f5",
            "a7445c730c0c452cadc4e208945ebd12",
            "d5e4b00d17d848c68837bae578390bc2",
            "be606e6837cc451da8bfc5f645e1bb0d",
            "6fbbf5d207024393b77fcd669664032f",
            "818a2e7e941548fbb418ed194abe0e15",
            "8425f10b8c314f499c66ff3a42ac6a06",
            "a7be250e012c42848aceaac7bcf7c8c0",
            "8ddd662d53db4c89b4e66c8631db6ee0",
            "3c3f240f3a6c4b03bc7dd31a934640e1",
            "d0f26ef8b5d0483aa42e4710fb9f2281",
            "a53ab6daad5b40f4a5448f3fdd21a5d0",
            "af15ee3490ff4314816230df3b18a0c8",
            "aaf11ebeac1744c1ab923eedecf3c5b4",
            "773b26c70f0344bb83459a433cca8890",
            "b7373e827b5549fb80203165645801b6",
            "2a64a4f892244ea7864b67a857b6b5fe",
            "a917c0689beb41308b85a80f2102e4e7",
            "b7d9fe4f546d493fadf841d728b30bef",
            "499145fc7260454ab6a6a40ef7b50e69",
            "ca21e67c239a41c799f49b5d80747bc3",
            "e30c3368eac7450ca45d096e518dc7da",
            "4b9ae843d41240d0a49123b974236739",
            "efcc2a607d844b4b8f18344192b438fe",
            "1c198f972dec48899508325c36682757",
            "c1464be6e1f54a388b9f6d9dcaa9a917",
            "4711b46f9f944356a6da77200ca9cc5f",
            "8f28e42ce9814806ac3efb82cba04d89",
            "a3aa22aa174c4e02a9f6c5610bc50959",
            "4a3db0ff39ef4fa8b94fb0f45f020ccd",
            "bd7543c4c3a146faad33ac520f6e8aec",
            "c1599ddb5a8f41deb48e7d9af93a6b80",
            "0afc9c3c55d84d98afb2a665faf3e294",
            "bfbeab0fb29a4287b53890a1197e3c8e",
            "0c1f28e756724f49aaf4f961dc97b9e1",
            "4484ce0d5dfb40ff8b78076ccc66c28b",
            "176468feb21d409ba34269eae5fe00e0",
            "2cffaa7757e64d2aa47bf25cfbd8db0d",
            "ab441e98a3104e38bea9e8cc5c19957d",
            "51774329b4b84eef8a51bffd4fad7c23",
            "842eefb0d6334614aedc57ce1457a075",
            "43ff71bcb9ce4bcda7ace9d3285b48cd",
            "95f0e89cbc6141c1b6a5c19fb7453299",
            "af394168dad946a5a4511d7609f1fd04",
            "4b7a8bc9e26f414d9a2667570accb554",
            "290b11fc7d644222a1a8db2b6e2f57df",
            "504d094cd96d4a4391ba9dfef45e9e8c",
            "d13c16c0b5d64592b4861d8cfdb3f797",
            "7348ddd1a48a471294b8a9e401ce4ad9",
            "2eec72b6ec3f4ddcb0a9b93c1f6bbb71",
            "762dea634b7440b5a6faa6434bcb6536",
            "df42a9f2a32d42348a4f753f2247c87a",
            "6975379874664dc3b80747063fcb2226",
            "ec07e48028e54231ada2999f584c85d8",
            "2243e578cf6d4e5d8fc5d52ee545fd41",
            "67ef2559123541ca994050bb1aa5dacf",
            "fe2863d6790840d1a771e2eed756166c",
            "24ffa1014c0f472aa25cb1d6b8f084dd",
            "59fef510094044708c73221f3ce3be86",
            "57eea769f7734ed38eb44d2cc515f7a8",
            "1f67323168b8401fb27f1d0b369dbce0",
            "3f6ef4f01e1d4ca1b4bbfabe7bb0907d",
            "684c1e5cdd2c4c63bf6c9879a14d1b79",
            "3b4230b857dd4d15978edd368c2cfad1",
            "79b2022c9a9246a7a3e27607bc11ea2f",
            "81cd3fe16a9f4fbdb2f77bf561f9f2f1",
            "5682fc7a8cd848719d64a738abbd75b7",
            "1edeb81aa72d4516b659ced67c70c8a7",
            "7cde14a3f68e429eb75a7e3a1d3c5c07",
            "24f851631f874a918ec92203653ebd55",
            "52764c0322cf4a2d83967c88559a9ad2",
            "d78ff57168bd4b5fbbd56f92abf7c5ba",
            "32fc92018a8c47e080f46d4542a03874",
            "7c8bd7d5dc9149c78a5b577211af96a0",
            "56d3bbd7d00b440bbc20e4ac5bfbc8d0",
            "4922e1e04b494c828c9473313a044378",
            "03b2dc603614433bbed3de6821b899c3",
            "0ce50bf6c469419cb3f3dd3d7d453332",
            "1f0933d837704f38bccee24f7f7b5c05",
            "c534e83a14db4e6eaf1da2c4627bfb21",
            "0594188d583c49fc8d8d912bf900b847",
            "76e0fd6b58e54fe882bffa2408ddf1d5",
            "433ba38e6fab4e36aad51e52e34bfb4e",
            "9ddeed44a9754799ac42034b56342c0a",
            "ea7d2c938b72477b9310533cc8c74da1",
            "300ed2e7b74848899f3493032420c8a5",
            "9a3fead3b0da48e99fc76fa965259a9b",
            "537e4e370af74fcab7af4a627f2fdb6d",
            "c712fb39b4da442f92d0e20288b929f5",
            "18b62c2093ea46c890567487042fc846",
            "79bd952c6e8f459488cb41bdaf4e79db",
            "f5d36466adc24a5098911becea66e035",
            "4d6d7f6a35c5489f9bb57da865069bc1",
            "71f32dfb37ba4f628afe3cbd15cdba91"
          ]
        },
        "id": "WGOrT266vGZ1",
        "outputId": "16420bed-6f42-49da-d45d-337d588f9cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/15:   0%|          | 0/8496 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d831f31de82b4d08bbf326af06fba5a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Average Loss: 0.2231\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 2/15:   0%|          | 0/8496 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7aec08851e3f44bfaa728bdfadeaf8ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Average Loss: 0.1462\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 3/15:   0%|          | 0/8496 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f33d739a6a942c383ec0dd2d4350975"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Average Loss: 0.1398\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 4/15:   0%|          | 0/8496 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "280aa54eda924886b3a090ef13c17530"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Average Loss: 0.1361\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 5/15:   0%|          | 0/8496 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2f75395c9f74fed98dd81fcf38292cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Average Loss: 0.1337\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 6/15:   0%|          | 0/8496 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "769db0b4d83948e4ae4f833379ee0f99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Average Loss: 0.1318\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 7/15:   0%|          | 0/8496 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70b6d01efea64b708b816208ee79e95f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Average Loss: 0.1305\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 8/15:   0%|          | 0/8496 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8425f10b8c314f499c66ff3a42ac6a06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Average Loss: 0.1294\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 9/15:   0%|          | 0/8496 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a917c0689beb41308b85a80f2102e4e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Average Loss: 0.1285\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 10/15:   0%|          | 0/8496 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3aa22aa174c4e02a9f6c5610bc50959"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Average Loss: 0.1277\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 11/15:   0%|          | 0/8496 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51774329b4b84eef8a51bffd4fad7c23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Average Loss: 0.1270\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 12/15:   0%|          | 0/8496 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "762dea634b7440b5a6faa6434bcb6536"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Average Loss: 0.1265\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 13/15:   0%|          | 0/8496 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f6ef4f01e1d4ca1b4bbfabe7bb0907d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Average Loss: 0.1260\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 14/15:   0%|          | 0/8496 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32fc92018a8c47e080f46d4542a03874"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Average Loss: 0.1256\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 15/15:   0%|          | 0/8496 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ddeed44a9754799ac42034b56342c0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Average Loss: 0.1251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text generation function\n",
        "def generate_text(model, start_text, max_length=100, temperature=1.0):\n",
        "    model.eval()\n",
        "    generated = [char_to_idx[ch] for ch in start_text]\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        input_seq = torch.tensor(generated[-seq_length:], dtype=torch.long).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(input_seq)\n",
        "        output = output[:, -1, :]\n",
        "\n",
        "        output = output / temperature\n",
        "        next_token_probs = F.softmax(output, dim=-1).squeeze()\n",
        "        next_token_idx = torch.multinomial(next_token_probs, 1).item()\n",
        "\n",
        "        generated.append(next_token_idx)\n",
        "\n",
        "    return ''.join([idx_to_char[idx] for idx in generated])"
      ],
      "metadata": {
        "id": "_8LVdHBKvLv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example text generation\n",
        "start_text = \"Hello How are you\"\n",
        "print(generate_text(model, start_text=start_text, temperature=0.7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyuEaQOYv264",
        "outputId": "93ff44b5-1622-4ce1-ca3c-e804cb6dd484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello How are you ?   Yeah , I ’ m can I ’ m are .   I want to need has the more were to in the different .   Why new\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, optimizer, epoch, file_path):\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, file_path)\n",
        "    print(f'Model saved to {file_path}')\n",
        "\n",
        "save_model(model, optimizer, num_epochs, 'gpt_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwSjiHrBwiFP",
        "outputId": "00af6cd2-7338-4b5d-c944-e35b57972d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to gpt_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model, optimizer, file_path):\n",
        "    checkpoint = torch.load(file_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    print(f'Model loaded from {file_path} at epoch {epoch}')\n",
        "    return epoch\n",
        "\n",
        "loaded_epoch = load_model(model, optimizer, 'gpt_model.pth')"
      ],
      "metadata": {
        "id": "itfSy7L265Cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4502a800-01f9-4ff0-f9ef-6ccc50a88785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from gpt_model.pth at epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-cd21664b2664>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(file_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DPORuMXUCOZu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}